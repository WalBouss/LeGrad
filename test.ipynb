{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please 'pip install apex'\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1d842b24e164bdfb797224009d297e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_assisted_decoding',\n '_auto_class',\n '_autoset_attn_implementation',\n '_backward_compatibility_gradient_checkpointing',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_beam_sample',\n '_beam_search',\n '_buffers',\n '_call_impl',\n '_check_and_enable_flash_attn_2',\n '_check_and_enable_sdpa',\n '_compiled_call_impl',\n '_constrained_beam_search',\n '_contrastive_search',\n '_convert_head_mask_to_5d',\n '_copy_lm_head_original_to_resized',\n '_create_repo',\n '_dispatch_accelerate_model',\n '_expand_inputs_for_generation',\n '_extract_past_from_model_output',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_from_config',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_candidate_generator',\n '_get_decoder_start_token_id',\n '_get_files_timestamps',\n '_get_logits_processor',\n '_get_logits_warper',\n '_get_name',\n '_get_no_split_modules',\n '_get_resized_embeddings',\n '_get_resized_lm_head',\n '_get_stopping_criteria',\n '_greedy_search',\n '_group_beam_search',\n '_has_unfinished_sequences',\n '_hf_peft_config_loaded',\n '_hook_rss_memory_post_forward',\n '_hook_rss_memory_pre_forward',\n '_init_weights',\n '_initialize_weights',\n '_is_full_backward_hook',\n '_is_hf_initialized',\n '_is_quantized_training_enabled',\n '_keep_in_fp32_modules',\n '_keep_in_fp32_modules',\n '_keys_to_ignore_on_load_missing',\n '_keys_to_ignore_on_load_unexpected',\n '_keys_to_ignore_on_save',\n '_load_from_state_dict',\n '_load_pretrained_model',\n '_load_pretrained_model_low_mem',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_initialize_input_ids_for_generation',\n '_maybe_warn_non_full_backward_hook',\n '_merge_criteria_processor_list',\n '_modules',\n '_named_members',\n '_no_split_modules',\n '_non_persistent_buffers_set',\n '_parameters',\n '_prepare_attention_mask_for_generation',\n '_prepare_decoder_input_ids_for_generation',\n '_prepare_encoder_decoder_kwargs_for_generation',\n '_prepare_generated_length',\n '_prepare_generation_config',\n '_prepare_model_inputs',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_reorder_cache',\n '_replicate_for_data_parallel',\n '_resize_token_embeddings',\n '_sample',\n '_save_to_state_dict',\n '_set_default_torch_dtype',\n '_set_gradient_checkpointing',\n '_skip_keys_device_placement',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_supports_cache_class',\n '_supports_flash_attn_2',\n '_supports_sdpa',\n '_temporary_reorder_cache',\n '_tie_encoder_decoder_weights',\n '_tie_or_clone_weights',\n '_tied_weights_keys',\n '_update_model_kwargs_for_generation',\n '_upload_modified_files',\n '_validate_generated_length',\n '_validate_model_class',\n '_validate_model_kwargs',\n '_version',\n '_wrapped_call_impl',\n 'active_adapter',\n 'active_adapters',\n 'add_adapter',\n 'add_memory_hooks',\n 'add_model_tags',\n 'add_module',\n 'apply',\n 'assisted_decoding',\n 'base_model',\n 'base_model_prefix',\n 'beam_sample',\n 'beam_search',\n 'bfloat16',\n 'buffers',\n 'build_conversation_input_ids',\n 'call_super_init',\n 'can_generate',\n 'children',\n 'compile',\n 'compute_transition_scores',\n 'config',\n 'config_class',\n 'constrained_beam_search',\n 'contrastive_search',\n 'cpu',\n 'create_extended_attention_mask_for_decoder',\n 'cuda',\n 'device',\n 'disable_adapters',\n 'disable_input_require_grads',\n 'double',\n 'dtype',\n 'dummy_inputs',\n 'dump_patches',\n 'enable_adapters',\n 'enable_input_require_grads',\n 'estimate_tokens',\n 'eval',\n 'extra_repr',\n 'float',\n 'floating_point_ops',\n 'forward',\n 'framework',\n 'from_pretrained',\n 'generate',\n 'generation_config',\n 'get_adapter_state_dict',\n 'get_buffer',\n 'get_decoder',\n 'get_extended_attention_mask',\n 'get_extra_state',\n 'get_head_mask',\n 'get_input_embeddings',\n 'get_memory_footprint',\n 'get_output_embeddings',\n 'get_parameter',\n 'get_position_embeddings',\n 'get_submodule',\n 'gradient_checkpointing_disable',\n 'gradient_checkpointing_enable',\n 'greedy_search',\n 'group_beam_search',\n 'half',\n 'init_weights',\n 'invert_attention_mask',\n 'ipu',\n 'is_gradient_checkpointing',\n 'is_parallelizable',\n 'lm_head',\n 'load_adapter',\n 'load_state_dict',\n 'main_input_name',\n 'model',\n 'model_tags',\n 'modules',\n 'name_or_path',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_parameters',\n 'parameters',\n 'post_init',\n 'prepare_inputs_for_generation',\n 'prune_heads',\n 'push_to_hub',\n 'register_backward_hook',\n 'register_buffer',\n 'register_for_auto_class',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_memory_hooks_state',\n 'resize_position_embeddings',\n 'resize_token_embeddings',\n 'retrieve_modules_from_names',\n 'reverse_bettertransformer',\n 'sample',\n 'save_pretrained',\n 'set_adapter',\n 'set_decoder',\n 'set_extra_state',\n 'set_input_embeddings',\n 'set_output_embeddings',\n 'share_memory',\n 'state_dict',\n 'supports_gradient_checkpointing',\n 'tie_weights',\n 'to',\n 'to_bettertransformer',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'vocab_size',\n 'warn_if_padding_and_no_attention_mask',\n 'warnings_issued',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"THUDM/cogagent-chat-hf\")\n",
    "\n",
    "# Explore the attributes\n",
    "dir(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:09:32.995301Z",
     "start_time": "2024-05-14T13:08:20.702975Z"
    }
   },
   "id": "673723a69791f393",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule: model - CogAgentModel(\n",
      "  (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "  (layers): ModuleList(\n",
      "    (0-31): 32 x CogAgentDecoderLayer(\n",
      "      (self_attn): VisionExpertAttention(\n",
      "        (rotary_emb): RotaryEmbedding()\n",
      "        (vision_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (vision_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (language_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (language_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      )\n",
      "      (cross_attn): CrossAttention(\n",
      "        (query): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (key_value): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "        (dense): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "      )\n",
      "      (mlp): VisionExpertMLP(\n",
      "        (language_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (vision_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (input_layernorm): RMSNorm()\n",
      "      (post_attention_layernorm): RMSNorm()\n",
      "      (post_cross_attention_layernorm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      "  (vision): EVA2CLIPModel(\n",
      "    (patch_embedding): PatchEmbedding(\n",
      "      (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (position_embedding): Embedding(257, 1792)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-62): 63 x TransformerLayer(\n",
      "          (input_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "          (attention): Attention(\n",
      "            (query_key_value): Linear(in_features=1792, out_features=5376, bias=True)\n",
      "            (dense): Linear(in_features=1792, out_features=1792, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (mlp): MLP(\n",
      "            (activation_fn): GELUActivation()\n",
      "            (fc1): Linear(in_features=1792, out_features=15360, bias=True)\n",
      "            (fc2): Linear(in_features=15360, out_features=1792, bias=True)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear_proj): GLU(\n",
      "      (linear_proj): Linear(in_features=1792, out_features=4096, bias=False)\n",
      "      (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "      (act1): GELU(approximate='none')\n",
      "      (dense_h_to_4h): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (dense_4h_to_h): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (cross_vision): CrossVisionModel(\n",
      "    (vit): Eva2LargeEncoder(\n",
      "      (model): EVAVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "        )\n",
      "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "        (rope): VisionRotaryEmbeddingFast()\n",
      "        (blocks): ModuleList(\n",
      "          (0-23): 24 x Block(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): Attention(\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (rope): VisionRotaryEmbeddingFast()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): SwiGLU(\n",
      "              (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (act): SiLU()\n",
      "              (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
      "              (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (patch_dropout): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Submodule: lm_head - Linear(in_features=4096, out_features=32000, bias=False)\n"
     ]
    }
   ],
   "source": [
    "# Print the top-level submodules\n",
    "for name, module in model.named_children():\n",
    "    print(f\"Submodule: {name} - {module}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:09:33.005001Z",
     "start_time": "2024-05-14T13:09:32.997464Z"
    }
   },
   "id": "f3e898ef42aa00c3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level submodules:\n",
      "Submodule: model - CogAgentModel(\n",
      "  (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "  (layers): ModuleList(\n",
      "    (0-31): 32 x CogAgentDecoderLayer(\n",
      "      (self_attn): VisionExpertAttention(\n",
      "        (rotary_emb): RotaryEmbedding()\n",
      "        (vision_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (vision_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (language_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (language_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      )\n",
      "      (cross_attn): CrossAttention(\n",
      "        (query): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (key_value): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "        (dense): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "      )\n",
      "      (mlp): VisionExpertMLP(\n",
      "        (language_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (vision_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (input_layernorm): RMSNorm()\n",
      "      (post_attention_layernorm): RMSNorm()\n",
      "      (post_cross_attention_layernorm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      "  (vision): EVA2CLIPModel(\n",
      "    (patch_embedding): PatchEmbedding(\n",
      "      (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (position_embedding): Embedding(257, 1792)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-62): 63 x TransformerLayer(\n",
      "          (input_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "          (attention): Attention(\n",
      "            (query_key_value): Linear(in_features=1792, out_features=5376, bias=True)\n",
      "            (dense): Linear(in_features=1792, out_features=1792, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (mlp): MLP(\n",
      "            (activation_fn): GELUActivation()\n",
      "            (fc1): Linear(in_features=1792, out_features=15360, bias=True)\n",
      "            (fc2): Linear(in_features=15360, out_features=1792, bias=True)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear_proj): GLU(\n",
      "      (linear_proj): Linear(in_features=1792, out_features=4096, bias=False)\n",
      "      (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "      (act1): GELU(approximate='none')\n",
      "      (dense_h_to_4h): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (dense_4h_to_h): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (cross_vision): CrossVisionModel(\n",
      "    (vit): Eva2LargeEncoder(\n",
      "      (model): EVAVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "        )\n",
      "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "        (rope): VisionRotaryEmbeddingFast()\n",
      "        (blocks): ModuleList(\n",
      "          (0-23): 24 x Block(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): Attention(\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (rope): VisionRotaryEmbeddingFast()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): SwiGLU(\n",
      "              (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (act): SiLU()\n",
      "              (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
      "              (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (patch_dropout): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Submodule: lm_head - Linear(in_features=4096, out_features=32000, bias=False)\n",
      "\n",
      "Inspecting submodule: model\n",
      "  Submodule: embed_tokens - Embedding(32000, 4096, padding_idx=0)\n",
      "  Submodule: layers - ModuleList(\n",
      "  (0-31): 32 x CogAgentDecoderLayer(\n",
      "    (self_attn): VisionExpertAttention(\n",
      "      (rotary_emb): RotaryEmbedding()\n",
      "      (vision_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "      (vision_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (language_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "      (language_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    )\n",
      "    (cross_attn): CrossAttention(\n",
      "      (query): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "      (key_value): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "      (dense): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "    )\n",
      "    (mlp): VisionExpertMLP(\n",
      "      (language_mlp): MLP(\n",
      "        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (vision_mlp): MLP(\n",
      "        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (input_layernorm): RMSNorm()\n",
      "    (post_attention_layernorm): RMSNorm()\n",
      "    (post_cross_attention_layernorm): RMSNorm()\n",
      "  )\n",
      ")\n",
      "  Submodule: norm - RMSNorm()\n",
      "  Submodule: vision - EVA2CLIPModel(\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "    (position_embedding): Embedding(257, 1792)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layers): ModuleList(\n",
      "      (0-62): 63 x TransformerLayer(\n",
      "        (input_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "        (attention): Attention(\n",
      "          (query_key_value): Linear(in_features=1792, out_features=5376, bias=True)\n",
      "          (dense): Linear(in_features=1792, out_features=1792, bias=True)\n",
      "          (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): MLP(\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=1792, out_features=15360, bias=True)\n",
      "          (fc2): Linear(in_features=15360, out_features=1792, bias=True)\n",
      "        )\n",
      "        (post_attention_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_proj): GLU(\n",
      "    (linear_proj): Linear(in_features=1792, out_features=4096, bias=False)\n",
      "    (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "    (act1): GELU(approximate='none')\n",
      "    (dense_h_to_4h): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "    (dense_4h_to_h): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  )\n",
      ")\n",
      "  Submodule: cross_vision - CrossVisionModel(\n",
      "  (vit): Eva2LargeEncoder(\n",
      "    (model): EVAVisionTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (rope): VisionRotaryEmbeddingFast()\n",
      "      (blocks): ModuleList(\n",
      "        (0-23): 24 x Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (rope): VisionRotaryEmbeddingFast()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): SwiGLU(\n",
      "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "            (act): SiLU()\n",
      "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
      "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (head): Linear(in_features=1024, out_features=768, bias=True)\n",
      "      (patch_dropout): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Inspecting submodule: lm_head\n"
     ]
    }
   ],
   "source": [
    "# Print the top-level submodules to identify possible visual components\n",
    "print(\"Top-level submodules:\")\n",
    "for name, module in model.named_children():\n",
    "    print(f\"Submodule: {name} - {module}\")\n",
    "\n",
    "# Drill down into specific submodules if necessary\n",
    "for name, module in model.named_children():\n",
    "    print(f\"\\nInspecting submodule: {name}\")\n",
    "    for sub_name, sub_module in module.named_children():\n",
    "        print(f\"  Submodule: {sub_name} - {sub_module}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:09:33.015946Z",
     "start_time": "2024-05-14T13:09:33.005858Z"
    }
   },
   "id": "251e32205c3f6729",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:09:33.017959Z",
     "start_time": "2024-05-14T13:09:33.016654Z"
    }
   },
   "id": "78f6f3a9947a6ce3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T13:09:33.021109Z",
     "start_time": "2024-05-14T13:09:33.019753Z"
    }
   },
   "id": "47ec08d372949ce",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
