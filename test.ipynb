{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-14T09:17:56.001426Z",
     "start_time": "2024-05-14T09:17:54.492298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Use torch type as:torch.float16 with device:cpu========\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b868e5d599b04b7da4b5b98aa1ad1a6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "model-00001-of-00008.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95c17533888d4c66bf7a40fb83972d42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 43\u001B[0m\n\u001B[1;32m     35\u001B[0m     model \u001B[38;5;241m=\u001B[39m AutoModelForCausalLM\u001B[38;5;241m.\u001B[39mfrom_pretrained(\n\u001B[1;32m     36\u001B[0m         MODEL_PATH,\n\u001B[1;32m     37\u001B[0m         torch_dtype\u001B[38;5;241m=\u001B[39mtorch_type,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     40\u001B[0m         trust_remote_code\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     41\u001B[0m     )\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 43\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mAutoModelForCausalLM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[43mMODEL_PATH\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlow_cpu_mem_usage\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m        \u001B[49m\u001B[43mload_in_4bit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquant\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(DEVICE)\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Define LeWrapper and LePreprocess classes\u001B[39;00m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mLeWrapper\u001B[39;00m(nn\u001B[38;5;241m.\u001B[39mModule):\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py:558\u001B[0m, in \u001B[0;36m_BaseAutoModelClass.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m    556\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    557\u001B[0m         \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mregister(config\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, model_class, exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 558\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmodel_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    559\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mhub_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    560\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(config) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m    562\u001B[0m     model_class \u001B[38;5;241m=\u001B[39m _get_model_class(config, \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_model_mapping)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/transformers/modeling_utils.py:3436\u001B[0m, in \u001B[0;36mPreTrainedModel.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001B[0m\n\u001B[1;32m   3433\u001B[0m \u001B[38;5;66;03m# We'll need to download and cache each checkpoint shard if the checkpoint is sharded.\u001B[39;00m\n\u001B[1;32m   3434\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_sharded:\n\u001B[1;32m   3435\u001B[0m     \u001B[38;5;66;03m# rsolved_archive_file becomes a list of files that point to the different checkpoint shards in this case.\u001B[39;00m\n\u001B[0;32m-> 3436\u001B[0m     resolved_archive_file, sharded_metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_checkpoint_shard_files\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresolved_archive_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3440\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3441\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3442\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3445\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3446\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3447\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3448\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3449\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3451\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   3452\u001B[0m     is_safetensors_available()\n\u001B[1;32m   3453\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resolved_archive_file, \u001B[38;5;28mstr\u001B[39m)\n\u001B[1;32m   3454\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m resolved_archive_file\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.safetensors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   3455\u001B[0m ):\n\u001B[1;32m   3456\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m safe_open(resolved_archive_file, framework\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/transformers/utils/hub.py:1038\u001B[0m, in \u001B[0;36mget_checkpoint_shard_files\u001B[0;34m(pretrained_model_name_or_path, index_filename, cache_dir, force_download, proxies, resume_download, local_files_only, token, user_agent, revision, subfolder, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m   1035\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m shard_filename \u001B[38;5;129;01min\u001B[39;00m tqdm(shard_filenames, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDownloading shards\u001B[39m\u001B[38;5;124m\"\u001B[39m, disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m show_progress_bar):\n\u001B[1;32m   1036\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1037\u001B[0m         \u001B[38;5;66;03m# Load from URL\u001B[39;00m\n\u001B[0;32m-> 1038\u001B[0m         cached_filename \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1039\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1040\u001B[0m \u001B[43m            \u001B[49m\u001B[43mshard_filename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1041\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1042\u001B[0m \u001B[43m            \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1043\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1044\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1045\u001B[0m \u001B[43m            \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1046\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1047\u001B[0m \u001B[43m            \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1048\u001B[0m \u001B[43m            \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1049\u001B[0m \u001B[43m            \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1050\u001B[0m \u001B[43m            \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_commit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1051\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1052\u001B[0m     \u001B[38;5;66;03m# We have already dealt with RepositoryNotFoundError and RevisionNotFoundError when getting the index, so\u001B[39;00m\n\u001B[1;32m   1053\u001B[0m     \u001B[38;5;66;03m# we don't have to catch them here.\u001B[39;00m\n\u001B[1;32m   1054\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/transformers/utils/hub.py:398\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 398\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    406\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    407\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    413\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/huggingface_hub/file_download.py:1457\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001B[0m\n\u001B[1;32m   1454\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m local_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1455\u001B[0m             _check_disk_space(expected_size, local_dir)\n\u001B[0;32m-> 1457\u001B[0m     \u001B[43mhttp_get\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1458\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl_to_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemp_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1460\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1461\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1463\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexpected_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexpected_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1464\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1466\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m local_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1467\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStoring \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in cache at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mblob_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/huggingface_hub/file_download.py:524\u001B[0m, in \u001B[0;36mhttp_get\u001B[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, _nb_retries)\u001B[0m\n\u001B[1;32m    522\u001B[0m new_resume_size \u001B[38;5;241m=\u001B[39m resume_size\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 524\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDOWNLOAD_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m:\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# filter out keep-alive new chunks\u001B[39;49;00m\n\u001B[1;32m    526\u001B[0m \u001B[43m            \u001B[49m\u001B[43mprogress\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/urllib3/response.py:1033\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1031\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1032\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 1033\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1035\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m   1036\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/urllib3/response.py:925\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    922\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m amt:\n\u001B[1;32m    923\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer\u001B[38;5;241m.\u001B[39mget(amt)\n\u001B[0;32m--> 925\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raw_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    927\u001B[0m flush_decoder \u001B[38;5;241m=\u001B[39m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[1;32m    929\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/urllib3/response.py:852\u001B[0m, in \u001B[0;36mHTTPResponse._raw_read\u001B[0;34m(self, amt, read1)\u001B[0m\n\u001B[1;32m    849\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 852\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mread1\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    853\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m    854\u001B[0m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[1;32m    855\u001B[0m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    860\u001B[0m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[1;32m    861\u001B[0m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[1;32m    862\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/site-packages/urllib3/response.py:835\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt, read1)\u001B[0m\n\u001B[1;32m    832\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread1()\n\u001B[1;32m    833\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    834\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 835\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/http/client.py:473\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[1;32m    471\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[1;32m    472\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[0;32m--> 473\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    476\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/ssl.py:1315\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1312\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1313\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1314\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1315\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1316\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1317\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mlx/lib/python3.11/ssl.py:1167\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1165\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1166\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1167\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1168\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1169\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# CogVLM_Chat_Demo_with_LeGrad.ipynb\n",
    "\n",
    "# This is a demo for using CogAgent and CogVLM in CLI with LeGrad functionality\n",
    "# Make sure you have installed vicuna-7b-v1.5 tokenizer model (https://huggingface.co/lmsys/vicuna-7b-v1.5), full checkpoint of vicuna-7b-v1.5 LLM is not required.\n",
    "# Strongly suggest to use GPU with bfloat16 support, otherwise, it will be slow.\n",
    "# Mention that only one picture can be processed at one conversation, which means you can not replace or insert another picture during the conversation.\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoModelForCausalLM, LlamaTokenizer\n",
    "\n",
    "# LeGrad imports and utils (ensure these are defined as per your original code)\n",
    "from legrad import hooked_resblock_forward, hooked_attention_forward, vit_dynamic_size_forward, min_max\n",
    "\n",
    "# Simulate argparse\n",
    "class Args:\n",
    "    quant = None\n",
    "    from_pretrained = \"THUDM/cogagent-chat-hf\"\n",
    "    local_tokenizer = \"lmsys/vicuna-7b-v1.5\"\n",
    "    fp16 = False\n",
    "    bf16 = False\n",
    "\n",
    "args = Args()\n",
    "MODEL_PATH = args.from_pretrained\n",
    "TOKENIZER_PATH = args.local_tokenizer\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "torch_type = torch.bfloat16 if args.bf16 else torch.float16\n",
    "\n",
    "print(f\"========Use torch type as:{torch_type} with device:{DEVICE}========\\n\\n\")\n",
    "\n",
    "if args.quant:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        torch_dtype=torch_type,\n",
    "        low_cpu_mem_usage=True,\n",
    "        load_in_4bit=True,\n",
    "        trust_remote_code=True\n",
    "    ).eval()\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_PATH,\n",
    "        torch_dtype=torch_type,\n",
    "        low_cpu_mem_usage=True,\n",
    "        load_in_4bit=args.quant is not None,\n",
    "        trust_remote_code=True\n",
    "    ).to(DEVICE).eval()\n",
    "\n",
    "# Define LeWrapper and LePreprocess classes\n",
    "class LeWrapper(nn.Module):\n",
    "    def __init__(self, model, layer_index=-2):\n",
    "        super(LeWrapper, self).__init__()\n",
    "        for attr in dir(model):\n",
    "            if not attr.startswith('__'):\n",
    "                setattr(self, attr, getattr(model, attr))\n",
    "        self._activate_hooks(layer_index=layer_index)\n",
    "\n",
    "    def _activate_hooks(self, layer_index):\n",
    "        print('Activating necessary hooks and gradients ....')\n",
    "        if isinstance(self.visual, VisionTransformer):\n",
    "            self.visual.forward = types.MethodType(vit_dynamic_size_forward, self.visual)\n",
    "            self.patch_size = self.visual.patch_size[0]\n",
    "            self.starting_depth = layer_index if layer_index >= 0 else len(self.visual.transformer.resblocks) + layer_index\n",
    "            if self.visual.attn_pool is None:\n",
    "                self.model_type = 'clip'\n",
    "                self._activate_self_attention_hooks()\n",
    "            else:\n",
    "                self.model_type = 'coca'\n",
    "                self._activate_att_pool_hooks(layer_index=layer_index)\n",
    "        elif isinstance(self.visual, TimmModel):\n",
    "            self.visual.trunk.dynamic_img_size = True\n",
    "            self.visual.trunk.patch_embed.dynamic_img_size = True\n",
    "            self.visual.trunk.patch_embed.strict_img_size = False\n",
    "            self.visual.trunk.patch_embed.flatten = False\n",
    "            self.visual.trunk.patch_embed.output_fmt = 'NHWC'\n",
    "            self.model_type = 'timm_siglip'\n",
    "            self.patch_size = self.visual.trunk.patch_embed.patch_size[0]\n",
    "            self.starting_depth = layer_index if layer_index >= 0 else len(self.visual.trunk.blocks) + layer_index\n",
    "            self._activate_timm_attn_pool_hooks(layer_index=layer_index)\n",
    "        else:\n",
    "            raise ValueError(\"Model currently not supported, see legrad.list_pretrained() for a list of available models\")\n",
    "        print('Hooks and gradients activated!')\n",
    "\n",
    "    def _activate_self_attention_hooks(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            param.requires_grad = False\n",
    "            if name.startswith('visual.transformer.resblocks'):\n",
    "                depth = int(name.split('visual.transformer.resblocks.')[-1].split('.')[0])\n",
    "                if depth >= self.starting_depth:\n",
    "                    param.requires_grad = True\n",
    "        for layer in range(self.starting_depth, len(self.visual.transformer.resblocks)):\n",
    "            self.visual.transformer.resblocks[layer].attn.forward = types.MethodType(hooked_attention_forward, self.visual.transformer.resblocks[layer].attn)\n",
    "            self.visual.transformer.resblocks[layer].forward = types.MethodType(hooked_resblock_forward, self.visual.transformer.resblocks[layer])\n",
    "\n",
    "    def compute_legrad(self, text_embedding, image=None, apply_correction=True):\n",
    "        if 'clip' in self.model_type:\n",
    "            return self.compute_legrad_clip(text_embedding, image)\n",
    "        elif 'siglip' in self.model_type:\n",
    "            return self.compute_legrad_siglip(text_embedding, image, apply_correction=apply_correction)\n",
    "        elif 'coca' in self.model_type:\n",
    "            return self.compute_legrad_coca(text_embedding, image)\n",
    "\n",
    "    def compute_legrad_clip(self, text_embedding, image=None):\n",
    "        num_prompts = text_embedding.shape[0]\n",
    "        if image is not None:\n",
    "            _ = self.encode_image(image)\n",
    "        blocks_list = list(dict(self.visual.transformer.resblocks.named_children()).values())\n",
    "        image_features_list = []\n",
    "        for layer in range(self.starting_depth, len(self.visual.transformer.resblocks)):\n",
    "            intermediate_feat = self.visual.transformer.resblocks[layer].feat_post_mlp\n",
    "            intermediate_feat = self.visual.ln_post(intermediate_feat.mean(dim=0)) @ self.visual.proj\n",
    "            intermediate_feat = F.normalize(intermediate_feat, dim=-1)\n",
    "            image_features_list.append(intermediate_feat)\n",
    "        num_tokens = blocks_list[-1].feat_post_mlp.shape[0] - 1\n",
    "        w = h = int(math.sqrt(num_tokens))\n",
    "        accum_expl_map = 0\n",
    "        for layer, (blk, img_feat) in enumerate(zip(blocks_list[self.starting_depth:], image_features_list)):\n",
    "            self.visual.zero_grad()\n",
    "            sim = text_embedding @ img_feat.transpose(-1, -2)\n",
    "            one_hot = F.one_hot(torch.arange(0, num_prompts)).float().requires_grad_(True).to(text_embedding.device)\n",
    "            one_hot = torch.sum(one_hot * sim)\n",
    "            attn_map = blocks_list[self.starting_depth + layer].attn.attention_map\n",
    "            grad = torch.autograd.grad(one_hot, [attn_map], retain_graph=True, create_graph=True)[0]\n",
    "            grad = rearrange(grad, '(b h) n m -> b h n m', b=num_prompts)\n",
    "            grad = torch.clamp(grad, min=0.)\n",
    "            image_relevance = grad.mean(dim=1).mean(dim=1)[:, 1:]\n",
    "            expl_map = rearrange(image_relevance, 'b (w h) -> 1 b w h', w=w, h=h)\n",
    "            expl_map = F.interpolate(expl_map, scale_factor=self.patch_size, mode='bilinear')\n",
    "            accum_expl_map += expl_map\n",
    "        accum_expl_map = min_max(accum_expl_map)\n",
    "        return accum_expl_map\n",
    "\n",
    "class LePreprocess(nn.Module):\n",
    "    def __init__(self, preprocess, image_size):\n",
    "        super(LePreprocess, self).__init__()\n",
    "        self.transform = Compose(\n",
    "            [\n",
    "                Resize((image_size, image_size), interpolation=InterpolationMode.BICUBIC),\n",
    "                preprocess.transforms[-3],\n",
    "                preprocess.transforms[-2],\n",
    "                preprocess.transforms[-1],\n",
    "            ]\n",
    "        )\n",
    "    def forward(self, image):\n",
    "        return self.transform(image)\n",
    "\n",
    "# Wrapping the CogVLM model with LeGrad functionality\n",
    "model = LeWrapper(model)\n",
    "\n",
    "# Function to chat and compute LeGrad\n",
    "def chat_with_model(image_path, queries):\n",
    "    if image_path:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "    else:\n",
    "        image = None\n",
    "    \n",
    "    history = []\n",
    "    text_only_first_query = image is None\n",
    "\n",
    "    for query in queries:\n",
    "        if query == \"clear\":\n",
    "            history.clear()\n",
    "            continue\n",
    "\n",
    "        if image is None:\n",
    "            if text_only_first_query:\n",
    "                query = text_only_template.format(query)\n",
    "                text_only_first_query = False\n",
    "            else:\n",
    "                old_prompt = ''\n",
    "                for old_query, response in history:\n",
    "                    old_prompt += old_query + \" \" + response + \"\\n\"\n",
    "                query = old_prompt + f\"USER: {query} ASSISTANT:\"\n",
    "\n",
    "        if image is None:\n",
    "            input_by_model = model.build_conversation_input_ids(tokenizer, query=query, history=history, template_version='base')\n",
    "        else:\n",
    "            input_by_model = model.build_conversation_input_ids(tokenizer, query=query, history=history, images=[image])\n",
    "\n",
    "        inputs = {\n",
    "            'input_ids': input_by_model['input_ids'].unsqueeze(0).to(DEVICE),\n",
    "            'token_type_ids': input_by_model['token_type_ids'].unsqueeze(0).to(DEVICE),\n",
    "            'attention_mask': input_by_model['attention_mask'].unsqueeze(0).to(DEVICE),\n",
    "            'images': [[input_by_model['images'][0].to(DEVICE).to(torch_type)]] if image is not None else None,\n",
    "        }\n",
    "        if 'cross_images' in input_by_model and input_by_model['cross_images']:\n",
    "            inputs['cross_images'] = [[input_by_model['cross_images'][0].to(DEVICE).to(torch_type)]]\n",
    "\n",
    "        # add any transformers params here.\n",
    "        gen_kwargs = {\"max_length\": 2048, \"do_sample\": False}  # \"temperature\": 0.9\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, **gen_kwargs)\n",
    "            outputs = outputs[:, inputs['input_ids'].shape[1]:]\n",
    "            response = tokenizer.decode(outputs[0])\n",
    "            response = response.split(\"</s>\")[0]\n",
    "            print(\"\\nCog:\", response)\n",
    "        history.append((query, response))\n",
    "        \n",
    "        # Compute LeGrad explanation map\n",
    "        text_embedding = model.encode_text(tokenizer([query]).to(DEVICE), normalize=True)\n",
    "        explainability_map = model.compute_legrad_clip(image=image, text_embedding=text_embedding)\n",
    "        visualize(heatmaps=explainability_map, image=image)\n",
    "\n",
    "# Example usage\n",
    "image_path = \"path/to/your/image.jpg\"  # Provide path to your image\n",
    "queries = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"Can you tell me more about this image?\",\n",
    "    \"What objects can you identify?\"\n",
    "]\n",
    "\n",
    "chat_with_model(image_path, queries)\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please 'pip install apex'\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "48ca5410bf394e71950b048b18ff3bf7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_assisted_decoding',\n '_auto_class',\n '_autoset_attn_implementation',\n '_backward_compatibility_gradient_checkpointing',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_beam_sample',\n '_beam_search',\n '_buffers',\n '_call_impl',\n '_check_and_enable_flash_attn_2',\n '_check_and_enable_sdpa',\n '_compiled_call_impl',\n '_constrained_beam_search',\n '_contrastive_search',\n '_convert_head_mask_to_5d',\n '_copy_lm_head_original_to_resized',\n '_create_repo',\n '_dispatch_accelerate_model',\n '_expand_inputs_for_generation',\n '_extract_past_from_model_output',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_from_config',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_candidate_generator',\n '_get_decoder_start_token_id',\n '_get_files_timestamps',\n '_get_logits_processor',\n '_get_logits_warper',\n '_get_name',\n '_get_no_split_modules',\n '_get_resized_embeddings',\n '_get_resized_lm_head',\n '_get_stopping_criteria',\n '_greedy_search',\n '_group_beam_search',\n '_has_unfinished_sequences',\n '_hf_peft_config_loaded',\n '_hook_rss_memory_post_forward',\n '_hook_rss_memory_pre_forward',\n '_init_weights',\n '_initialize_weights',\n '_is_full_backward_hook',\n '_is_hf_initialized',\n '_is_quantized_training_enabled',\n '_keep_in_fp32_modules',\n '_keep_in_fp32_modules',\n '_keys_to_ignore_on_load_missing',\n '_keys_to_ignore_on_load_unexpected',\n '_keys_to_ignore_on_save',\n '_load_from_state_dict',\n '_load_pretrained_model',\n '_load_pretrained_model_low_mem',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_initialize_input_ids_for_generation',\n '_maybe_warn_non_full_backward_hook',\n '_merge_criteria_processor_list',\n '_modules',\n '_named_members',\n '_no_split_modules',\n '_non_persistent_buffers_set',\n '_parameters',\n '_prepare_attention_mask_for_generation',\n '_prepare_decoder_input_ids_for_generation',\n '_prepare_encoder_decoder_kwargs_for_generation',\n '_prepare_generated_length',\n '_prepare_generation_config',\n '_prepare_model_inputs',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_reorder_cache',\n '_replicate_for_data_parallel',\n '_resize_token_embeddings',\n '_sample',\n '_save_to_state_dict',\n '_set_default_torch_dtype',\n '_set_gradient_checkpointing',\n '_skip_keys_device_placement',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_supports_cache_class',\n '_supports_flash_attn_2',\n '_supports_sdpa',\n '_temporary_reorder_cache',\n '_tie_encoder_decoder_weights',\n '_tie_or_clone_weights',\n '_tied_weights_keys',\n '_update_model_kwargs_for_generation',\n '_upload_modified_files',\n '_validate_generated_length',\n '_validate_model_class',\n '_validate_model_kwargs',\n '_version',\n '_wrapped_call_impl',\n 'active_adapter',\n 'active_adapters',\n 'add_adapter',\n 'add_memory_hooks',\n 'add_model_tags',\n 'add_module',\n 'apply',\n 'assisted_decoding',\n 'base_model',\n 'base_model_prefix',\n 'beam_sample',\n 'beam_search',\n 'bfloat16',\n 'buffers',\n 'build_conversation_input_ids',\n 'call_super_init',\n 'can_generate',\n 'children',\n 'compile',\n 'compute_transition_scores',\n 'config',\n 'config_class',\n 'constrained_beam_search',\n 'contrastive_search',\n 'cpu',\n 'create_extended_attention_mask_for_decoder',\n 'cuda',\n 'device',\n 'disable_adapters',\n 'disable_input_require_grads',\n 'double',\n 'dtype',\n 'dummy_inputs',\n 'dump_patches',\n 'enable_adapters',\n 'enable_input_require_grads',\n 'estimate_tokens',\n 'eval',\n 'extra_repr',\n 'float',\n 'floating_point_ops',\n 'forward',\n 'framework',\n 'from_pretrained',\n 'generate',\n 'generation_config',\n 'get_adapter_state_dict',\n 'get_buffer',\n 'get_decoder',\n 'get_extended_attention_mask',\n 'get_extra_state',\n 'get_head_mask',\n 'get_input_embeddings',\n 'get_memory_footprint',\n 'get_output_embeddings',\n 'get_parameter',\n 'get_position_embeddings',\n 'get_submodule',\n 'gradient_checkpointing_disable',\n 'gradient_checkpointing_enable',\n 'greedy_search',\n 'group_beam_search',\n 'half',\n 'init_weights',\n 'invert_attention_mask',\n 'ipu',\n 'is_gradient_checkpointing',\n 'is_parallelizable',\n 'lm_head',\n 'load_adapter',\n 'load_state_dict',\n 'main_input_name',\n 'model',\n 'model_tags',\n 'modules',\n 'name_or_path',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_parameters',\n 'parameters',\n 'post_init',\n 'prepare_inputs_for_generation',\n 'prune_heads',\n 'push_to_hub',\n 'register_backward_hook',\n 'register_buffer',\n 'register_for_auto_class',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_memory_hooks_state',\n 'resize_position_embeddings',\n 'resize_token_embeddings',\n 'retrieve_modules_from_names',\n 'reverse_bettertransformer',\n 'sample',\n 'save_pretrained',\n 'set_adapter',\n 'set_decoder',\n 'set_extra_state',\n 'set_input_embeddings',\n 'set_output_embeddings',\n 'share_memory',\n 'state_dict',\n 'supports_gradient_checkpointing',\n 'tie_weights',\n 'to',\n 'to_bettertransformer',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'vocab_size',\n 'warn_if_padding_and_no_attention_mask',\n 'warnings_issued',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"THUDM/cogagent-chat-hf\")\n",
    "\n",
    "# Explore the attributes\n",
    "dir(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T11:15:59.561384Z",
     "start_time": "2024-05-14T11:14:39.447109Z"
    }
   },
   "id": "673723a69791f393",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule: model - CogAgentModel(\n",
      "  (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "  (layers): ModuleList(\n",
      "    (0-31): 32 x CogAgentDecoderLayer(\n",
      "      (self_attn): VisionExpertAttention(\n",
      "        (rotary_emb): RotaryEmbedding()\n",
      "        (vision_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (vision_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (language_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (language_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      )\n",
      "      (cross_attn): CrossAttention(\n",
      "        (query): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (key_value): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "        (dense): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "      )\n",
      "      (mlp): VisionExpertMLP(\n",
      "        (language_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (vision_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (input_layernorm): RMSNorm()\n",
      "      (post_attention_layernorm): RMSNorm()\n",
      "      (post_cross_attention_layernorm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      "  (vision): EVA2CLIPModel(\n",
      "    (patch_embedding): PatchEmbedding(\n",
      "      (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (position_embedding): Embedding(257, 1792)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-62): 63 x TransformerLayer(\n",
      "          (input_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "          (attention): Attention(\n",
      "            (query_key_value): Linear(in_features=1792, out_features=5376, bias=True)\n",
      "            (dense): Linear(in_features=1792, out_features=1792, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (mlp): MLP(\n",
      "            (activation_fn): GELUActivation()\n",
      "            (fc1): Linear(in_features=1792, out_features=15360, bias=True)\n",
      "            (fc2): Linear(in_features=15360, out_features=1792, bias=True)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear_proj): GLU(\n",
      "      (linear_proj): Linear(in_features=1792, out_features=4096, bias=False)\n",
      "      (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "      (act1): GELU(approximate='none')\n",
      "      (dense_h_to_4h): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (dense_4h_to_h): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (cross_vision): CrossVisionModel(\n",
      "    (vit): Eva2LargeEncoder(\n",
      "      (model): EVAVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "        )\n",
      "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "        (rope): VisionRotaryEmbeddingFast()\n",
      "        (blocks): ModuleList(\n",
      "          (0-23): 24 x Block(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): Attention(\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (rope): VisionRotaryEmbeddingFast()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): SwiGLU(\n",
      "              (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (act): SiLU()\n",
      "              (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
      "              (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (patch_dropout): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Submodule: lm_head - Linear(in_features=4096, out_features=32000, bias=False)\n"
     ]
    }
   ],
   "source": [
    "# Print the top-level submodules\n",
    "for name, module in model.named_children():\n",
    "    print(f\"Submodule: {name} - {module}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T11:17:23.526065Z",
     "start_time": "2024-05-14T11:17:23.513549Z"
    }
   },
   "id": "f3e898ef42aa00c3",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please 'pip install apex'\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe089d5a95804f0e9b185a2ca09210f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level submodules:\n",
      "Submodule: model - CogAgentModel(\n",
      "  (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "  (layers): ModuleList(\n",
      "    (0-31): 32 x CogAgentDecoderLayer(\n",
      "      (self_attn): VisionExpertAttention(\n",
      "        (rotary_emb): RotaryEmbedding()\n",
      "        (vision_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (vision_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "        (language_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "        (language_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      )\n",
      "      (cross_attn): CrossAttention(\n",
      "        (query): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "        (key_value): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "        (dense): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "      )\n",
      "      (mlp): VisionExpertMLP(\n",
      "        (language_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (vision_mlp): MLP(\n",
      "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (input_layernorm): RMSNorm()\n",
      "      (post_attention_layernorm): RMSNorm()\n",
      "      (post_cross_attention_layernorm): RMSNorm()\n",
      "    )\n",
      "  )\n",
      "  (norm): RMSNorm()\n",
      "  (vision): EVA2CLIPModel(\n",
      "    (patch_embedding): PatchEmbedding(\n",
      "      (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "      (position_embedding): Embedding(257, 1792)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layers): ModuleList(\n",
      "        (0-62): 63 x TransformerLayer(\n",
      "          (input_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "          (attention): Attention(\n",
      "            (query_key_value): Linear(in_features=1792, out_features=5376, bias=True)\n",
      "            (dense): Linear(in_features=1792, out_features=1792, bias=True)\n",
      "            (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (mlp): MLP(\n",
      "            (activation_fn): GELUActivation()\n",
      "            (fc1): Linear(in_features=1792, out_features=15360, bias=True)\n",
      "            (fc2): Linear(in_features=15360, out_features=1792, bias=True)\n",
      "          )\n",
      "          (post_attention_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (linear_proj): GLU(\n",
      "      (linear_proj): Linear(in_features=1792, out_features=4096, bias=False)\n",
      "      (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "      (act1): GELU(approximate='none')\n",
      "      (dense_h_to_4h): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "      (dense_4h_to_h): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (cross_vision): CrossVisionModel(\n",
      "    (vit): Eva2LargeEncoder(\n",
      "      (model): EVAVisionTransformer(\n",
      "        (patch_embed): PatchEmbed(\n",
      "          (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "        )\n",
      "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "        (rope): VisionRotaryEmbeddingFast()\n",
      "        (blocks): ModuleList(\n",
      "          (0-23): 24 x Block(\n",
      "            (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (attn): Attention(\n",
      "              (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "              (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (rope): VisionRotaryEmbeddingFast()\n",
      "            )\n",
      "            (drop_path): Identity()\n",
      "            (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (mlp): SwiGLU(\n",
      "              (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "              (act): SiLU()\n",
      "              (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
      "              (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "              (drop): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (head): Linear(in_features=1024, out_features=768, bias=True)\n",
      "        (patch_dropout): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Submodule: lm_head - Linear(in_features=4096, out_features=32000, bias=False)\n",
      "\n",
      "Inspecting submodule: model\n",
      "  Submodule: embed_tokens - Embedding(32000, 4096, padding_idx=0)\n",
      "  Submodule: layers - ModuleList(\n",
      "  (0-31): 32 x CogAgentDecoderLayer(\n",
      "    (self_attn): VisionExpertAttention(\n",
      "      (rotary_emb): RotaryEmbedding()\n",
      "      (vision_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "      (vision_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "      (language_expert_query_key_value): Linear(in_features=4096, out_features=12288, bias=False)\n",
      "      (language_expert_dense): Linear(in_features=4096, out_features=4096, bias=False)\n",
      "    )\n",
      "    (cross_attn): CrossAttention(\n",
      "      (query): Linear(in_features=4096, out_features=1024, bias=False)\n",
      "      (key_value): Linear(in_features=1024, out_features=2048, bias=False)\n",
      "      (dense): Linear(in_features=1024, out_features=4096, bias=False)\n",
      "    )\n",
      "    (mlp): VisionExpertMLP(\n",
      "      (language_mlp): MLP(\n",
      "        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "      (vision_mlp): MLP(\n",
      "        (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "        (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "        (act_fn): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (input_layernorm): RMSNorm()\n",
      "    (post_attention_layernorm): RMSNorm()\n",
      "    (post_cross_attention_layernorm): RMSNorm()\n",
      "  )\n",
      ")\n",
      "  Submodule: norm - RMSNorm()\n",
      "  Submodule: vision - EVA2CLIPModel(\n",
      "  (patch_embedding): PatchEmbedding(\n",
      "    (proj): Conv2d(3, 1792, kernel_size=(14, 14), stride=(14, 14))\n",
      "    (position_embedding): Embedding(257, 1792)\n",
      "  )\n",
      "  (transformer): Transformer(\n",
      "    (layers): ModuleList(\n",
      "      (0-62): 63 x TransformerLayer(\n",
      "        (input_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "        (attention): Attention(\n",
      "          (query_key_value): Linear(in_features=1792, out_features=5376, bias=True)\n",
      "          (dense): Linear(in_features=1792, out_features=1792, bias=True)\n",
      "          (output_dropout): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (mlp): MLP(\n",
      "          (activation_fn): GELUActivation()\n",
      "          (fc1): Linear(in_features=1792, out_features=15360, bias=True)\n",
      "          (fc2): Linear(in_features=15360, out_features=1792, bias=True)\n",
      "        )\n",
      "        (post_attention_layernorm): LayerNorm((1792,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear_proj): GLU(\n",
      "    (linear_proj): Linear(in_features=1792, out_features=4096, bias=False)\n",
      "    (norm1): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n",
      "    (act1): GELU(approximate='none')\n",
      "    (dense_h_to_4h): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "    (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
      "    (dense_4h_to_h): Linear(in_features=11008, out_features=4096, bias=False)\n",
      "  )\n",
      ")\n",
      "  Submodule: cross_vision - CrossVisionModel(\n",
      "  (vit): Eva2LargeEncoder(\n",
      "    (model): EVAVisionTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14))\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (rope): VisionRotaryEmbeddingFast()\n",
      "      (blocks): ModuleList(\n",
      "        (0-23): 24 x Block(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (inner_attn_ln): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (rope): VisionRotaryEmbeddingFast()\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): SwiGLU(\n",
      "            (w1): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "            (w2): Linear(in_features=1024, out_features=2730, bias=True)\n",
      "            (act): SiLU()\n",
      "            (ffn_ln): LayerNorm((2730,), eps=1e-06, elementwise_affine=True)\n",
      "            (w3): Linear(in_features=2730, out_features=1024, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "      (head): Linear(in_features=1024, out_features=768, bias=True)\n",
      "      (patch_dropout): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Inspecting submodule: lm_head\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "# Load the CogVLM model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"THUDM/cogagent-chat-hf\")\n",
    "\n",
    "# Print the top-level submodules to identify possible visual components\n",
    "print(\"Top-level submodules:\")\n",
    "for name, module in model.named_children():\n",
    "    print(f\"Submodule: {name} - {module}\")\n",
    "\n",
    "# Drill down into specific submodules if necessary\n",
    "for name, module in model.named_children():\n",
    "    print(f\"\\nInspecting submodule: {name}\")\n",
    "    for sub_name, sub_module in module.named_children():\n",
    "        print(f\"  Submodule: {sub_name} - {sub_module}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-14T12:03:16.683083Z",
     "start_time": "2024-05-14T12:01:58.142219Z"
    }
   },
   "id": "251e32205c3f6729",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "78f6f3a9947a6ce3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
